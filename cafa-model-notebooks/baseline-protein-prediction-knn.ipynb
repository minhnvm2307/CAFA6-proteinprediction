{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-13T03:35:37.487096Z",
     "iopub.status.busy": "2025-12-13T03:35:37.486656Z",
     "iopub.status.idle": "2025-12-13T03:35:38.783489Z",
     "shell.execute_reply": "2025-12-13T03:35:38.781725Z",
     "shell.execute_reply.started": "2025-12-13T03:35:37.486958Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!kaggle kernels output kwahnguyen/baseline-protein-prediction -p ./cafa6-test/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:24.271468Z",
     "iopub.status.busy": "2025-12-14T08:25:24.270637Z",
     "iopub.status.idle": "2025-12-14T08:25:24.366530Z",
     "shell.execute_reply": "2025-12-14T08:25:24.365390Z",
     "shell.execute_reply.started": "2025-12-14T08:25:24.271427Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from kaggle_secrets import UserSecretsClient\n",
    "import os \n",
    "\n",
    "user_secrets = UserSecretsClient()\n",
    "os.environ[\"KAGGLE_KEY\"] = user_secrets.get_secret(\"KAGGLE_KEY\")\n",
    "os.environ[\"KAGGLE_USERNAME\"] = user_secrets.get_secret(\"KAGGLE_USERNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:27.489373Z",
     "iopub.status.busy": "2025-12-14T08:25:27.488545Z",
     "iopub.status.idle": "2025-12-14T08:25:29.752222Z",
     "shell.execute_reply": "2025-12-14T08:25:29.750895Z",
     "shell.execute_reply.started": "2025-12-14T08:25:27.489340Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading cafa-6-protein-function-prediction.zip to /kaggle/working\n",
      "  0%|                                               | 0.00/91.3M [00:00<?, ?B/s]\n",
      "100%|██████████████████████████████████████| 91.3M/91.3M [00:00<00:00, 1.39GB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c cafa-6-protein-function-prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:34.626712Z",
     "iopub.status.busy": "2025-12-14T08:25:34.626379Z",
     "iopub.status.idle": "2025-12-14T08:25:37.809708Z",
     "shell.execute_reply": "2025-12-14T08:25:37.808542Z",
     "shell.execute_reply.started": "2025-12-14T08:25:34.626681Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /kaggle/working/cafa-6-protein-function-prediction.zip\n",
      "  inflating: /kaggle/working/IA.tsv  \n",
      "  inflating: /kaggle/working/Test/testsuperset-taxon-list.tsv  \n",
      "  inflating: /kaggle/working/Test/testsuperset.fasta  \n",
      "  inflating: /kaggle/working/Train/go-basic.obo  \n",
      "  inflating: /kaggle/working/Train/train_sequences.fasta  \n",
      "  inflating: /kaggle/working/Train/train_taxonomy.tsv  \n",
      "  inflating: /kaggle/working/Train/train_terms.tsv  \n",
      "  inflating: /kaggle/working/sample_submission.tsv  \n"
     ]
    }
   ],
   "source": [
    "# !unzip /kaggle/working/cafa-6-protein-function-prediction.zip -d /kaggle/working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:42.200359Z",
     "iopub.status.busy": "2025-12-14T08:25:42.199779Z",
     "iopub.status.idle": "2025-12-14T08:25:49.607439Z",
     "shell.execute_reply": "2025-12-14T08:25:49.606270Z",
     "shell.execute_reply.started": "2025-12-14T08:25:42.200316Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting biopython\n",
      "  Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from biopython) (1.26.4)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2025.3.0)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2022.3.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->biopython) (2.4.1)\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2025.3.0)\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->biopython) (2022.3.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->biopython) (1.4.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->biopython) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->biopython) (2024.2.0)\n",
      "Downloading biopython-1.86-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: biopython\n",
      "Successfully installed biopython-1.86\n"
     ]
    }
   ],
   "source": [
    "# !pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:49.982746Z",
     "iopub.status.busy": "2025-12-14T08:25:49.982391Z",
     "iopub.status.idle": "2025-12-14T08:25:52.180500Z",
     "shell.execute_reply": "2025-12-14T08:25:52.179420Z",
     "shell.execute_reply.started": "2025-12-14T08:25:49.982712Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IA.tsv', 'Train', 'Test', 'sample_submission.tsv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "\n",
    "zip_path = \"cafa-6-protein-function-prediction.zip\"\n",
    "extract_dir = \"./cafa6_data\"\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "os.listdir(extract_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:54.825990Z",
     "iopub.status.busy": "2025-12-14T08:25:54.825646Z",
     "iopub.status.idle": "2025-12-14T08:25:54.832877Z",
     "shell.execute_reply": "2025-12-14T08:25:54.831756Z",
     "shell.execute_reply.started": "2025-12-14T08:25:54.825967Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['train_terms.tsv',\n",
       " 'train_taxonomy.tsv',\n",
       " 'go-basic.obo',\n",
       " 'train_sequences.fasta']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "dir_path = '../data/Train'\n",
    "os.listdir(dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:56.742503Z",
     "iopub.status.busy": "2025-12-14T08:25:56.742146Z",
     "iopub.status.idle": "2025-12-14T08:25:56.750621Z",
     "shell.execute_reply": "2025-12-14T08:25:56.749446Z",
     "shell.execute_reply.started": "2025-12-14T08:25:56.742474Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Calculating Naive Frequency given a sequence\n",
    "def naive_freq(sequence):\n",
    "    \"\"\"\n",
    "    Input: an amino acid sequence of variable length\n",
    "    Output: a list of shape (1, 20), each element standing for an amino acid and its frequency\n",
    "    \"\"\"\n",
    "    # Counting the appearance of each amino acid within the sequence\n",
    "    AMINO_ACIDS = 'ARNDCQEGHILKMFPSTWYV'\n",
    "\n",
    "    AA_TO_INDEX = {aa: i for i, aa in enumerate(AMINO_ACIDS)}\n",
    "\n",
    "    frequency_vector = [0] * 20\n",
    "\n",
    "    for amino_acid in sequence:\n",
    "        try:\n",
    "            index = AA_TO_INDEX[amino_acid]\n",
    "            frequency_vector[index] += 1\n",
    "        except KeyError:\n",
    "            print(f\"Warning: Skipping unknown amino acid {amino_acid}\")\n",
    "            pass\n",
    "\n",
    "    # Calculating frequencies for each amino acid\n",
    "    total_length = len(sequence)\n",
    "\n",
    "    normalized_vector = frequency_vector\n",
    "    if total_length > 0:\n",
    "        normalized_vector = [count / total_length for count in frequency_vector]\n",
    "\n",
    "    return normalized_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:25:59.253895Z",
     "iopub.status.busy": "2025-12-14T08:25:59.253542Z",
     "iopub.status.idle": "2025-12-14T08:25:59.264912Z",
     "shell.execute_reply": "2025-12-14T08:25:59.263686Z",
     "shell.execute_reply.started": "2025-12-14T08:25:59.253865Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "CTD_GROUPS_BY_LIST = {\n",
    "    \"Hydrophobicity\": {\n",
    "        1: {\"A\", \"V\", \"L\", \"I\", \"M\", \"F\", \"W\", \"C\"},               # Hydrophobic\n",
    "        2: {\"G\", \"H\", \"Y\", \"P\", \"T\", \"S\"},          # Neutral\n",
    "        3: {\"R\", \"K\", \"Q\", \"E\", \"D\", \"N\"}           # Polar\n",
    "    },\n",
    "\n",
    "    \"Charge\": {\n",
    "        1: {\"D\", \"E\"},      # Negative\n",
    "        2: {\"A\", \"G\", \"I\", \"L\", \"M\", \"F\", \"P\", \"Q\", \"S\", \"T\", \"W\", \"Y\", \"V\", \"N\", \"C\"}, # Neutral\n",
    "        3: {\"K\", \"R\", \"H\"}     # Positive\n",
    "    },\n",
    "\n",
    "    \"VanDerWaals\": {\n",
    "        1: {\"A\", \"G\", \"S\", \"C\"},  # Small\n",
    "        2: {\"T\", \"D\", \"P\", \"N\", \"V\"},   # Medium\n",
    "        3: {\"E\", \"Q\", \"L\", \"I\", \"F\", \"Y\", \"M\", \"H\", \"K\", \"R\", \"W\"}   # Large\n",
    "    },\n",
    "\n",
    "    \"Polarity\": {\n",
    "        1: {\"L\", \"A\", \"W\", \"F\", \"C\", \"M\", \"V\", \"I\", \"Y\"},   # Small\n",
    "        2: {\"P\", \"T\", \"S\", \"G\", \"H\"},    # Medium\n",
    "        3: {\"Q\", \"N\", \"E\", \"D\", \"K\", \"R\"}   # High\n",
    "    },\n",
    "\n",
    "    \"Polarizability\": {\n",
    "        1: {\"G\", \"A\", \"S\", \"D\", \"C\"},   # Small\n",
    "        2: {\"T\", \"P\", \"N\", \"H\", \"E\", \"Q\", \"K\"},   # Medium\n",
    "        3: {\"M\", \"I\", \"L\", \"V\", \"F\", \"Y\", \"W\", \"R\"}\n",
    "    },\n",
    "\n",
    "    \"SecondStructure\": {\n",
    "        1: {\"E\", \"A\", \"L\", \"M\", \"Q\", \"K\", \"R\", \"H\"},  # Helix\n",
    "        2: {\"V\", \"I\", \"Y\", \"C\", \"W\", \"F\", \"T\"},  # Strand\n",
    "        3: {\"G\", \"N\", \"P\", \"S\", \"D\"}  # Coil\n",
    "    },\n",
    "\n",
    "    \"Solvent\": {\n",
    "        1: {\"A\", \"L\", \"F\", \"C\", \"G\", \"I\", \"V\", \"W\"},  # Buried\n",
    "        2: {\"R\", \"K\", \"Q\", \"E\", \"D\", \"N\"},  # Intermediate\n",
    "        3: {\"M\", \"S\", \"P\", \"T\", \"H\", \"Y\"}  # Exposed\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_group(aa, property_map):\n",
    "    for g, aa_set in property_map.items():\n",
    "        if aa in aa_set:\n",
    "            return g\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:03.884667Z",
     "iopub.status.busy": "2025-12-14T08:26:03.883718Z",
     "iopub.status.idle": "2025-12-14T08:26:03.897108Z",
     "shell.execute_reply": "2025-12-14T08:26:03.896015Z",
     "shell.execute_reply.started": "2025-12-14T08:26:03.884638Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "def aa_ctd(sequence, physicochem):\n",
    "    \"\"\"\n",
    "    For this composition, we compute the statistics on groups divided by physicochemical properties:\n",
    "        e.g: By hydrophobicity, we have three groups:\n",
    "            Class 1: {A, G, V, L, I, M, F, W, P}\n",
    "            Class 2: {R, K, H}\n",
    "            Class 3: {S, T, Y, C, N, Q, D, E}\n",
    "\n",
    "    Amino Acid composition is made up of three subcompositions for each physicochemical property:\n",
    "    - Composition (C): The frequency of a group by the number of AAs\n",
    "    - Transition (T) :\n",
    "    Input: an amino acid sequence of variable length\n",
    "\n",
    "    \"\"\"\n",
    "    property_map = CTD_GROUPS_BY_LIST[physicochem]\n",
    "    L = len(sequence)\n",
    "\n",
    "    groups = []\n",
    "    for aa in sequence:\n",
    "        g = get_group(aa, property_map)\n",
    "        if g is not None:\n",
    "            groups.append(g)\n",
    "\n",
    "    L = len(groups)\n",
    "    if L == 0:\n",
    "        return [0.0] * 21  # safe fallback\n",
    "\n",
    "    # Count members of each group\n",
    "    N = {1: 0, 2: 0, 3: 0}\n",
    "    for g in groups:\n",
    "        N[g] += 1\n",
    "\n",
    "    composition = [N[1]/L, N[2]/L, N[3]/L]\n",
    "\n",
    "    # Transitions\n",
    "    T12 = T13 = T23 = 0\n",
    "    for i in range(L - 1):\n",
    "        g1, g2 = groups[i], groups[i + 1]\n",
    "        if g1 == g2:\n",
    "            continue\n",
    "        gmin, gmax = min(g1, g2), max(g1, g2)\n",
    "        if gmin == 1 and gmax == 2:\n",
    "            T12 += 1\n",
    "        elif gmin == 1 and gmax == 3:\n",
    "            T13 += 1\n",
    "        elif gmin == 2 and gmax == 3:\n",
    "            T23 += 1\n",
    "\n",
    "    denom = L - 1\n",
    "    transition = [T12/denom, T13/denom, T23/denom]\n",
    "\n",
    "    # Distribution\n",
    "    positions = {1: [], 2: [], 3: []}\n",
    "    for i, g in enumerate(groups):\n",
    "        positions[g].append(i + 1)\n",
    "\n",
    "    P_k = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
    "    distribution = []\n",
    "\n",
    "    for g in [1, 2, 3]:\n",
    "        pos_list = positions[g]\n",
    "        Ng = len(pos_list)\n",
    "        if Ng == 0:\n",
    "            distribution.extend([0.0]*5)\n",
    "            continue\n",
    "        for pk in P_k:\n",
    "            if pk == 0:\n",
    "                idx = 0\n",
    "            else:\n",
    "                idx = math.ceil(Ng * pk) - 1\n",
    "            distribution.append(pos_list[idx] / L)\n",
    "\n",
    "    return composition + transition + distribution\n",
    "\n",
    "sequence = \"AEAAAEAEEAAAAAEAEEEAAEEAEEEAAE\"\n",
    "ctd = aa_ctd(sequence, \"Hydrophobicity\")\n",
    "print(len(ctd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:06.854272Z",
     "iopub.status.busy": "2025-12-14T08:26:06.853812Z",
     "iopub.status.idle": "2025-12-14T08:26:06.860670Z",
     "shell.execute_reply": "2025-12-14T08:26:06.859408Z",
     "shell.execute_reply.started": "2025-12-14T08:26:06.854245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def dipeptide_composition(seq):\n",
    "    \"\"\"Compute dipeptide composition.\"\"\"\n",
    "    AA = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    dipeptides = [a+b for a in AA for b in AA]\n",
    "    seq = seq.upper()\n",
    "    length = len(seq)-1 if len(seq)>1 else 1\n",
    "    return [sum(1 for i in range(len(seq)-1) if seq[i]+seq[i+1]==dp)/length for dp in dipeptides]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:09.011801Z",
     "iopub.status.busy": "2025-12-14T08:26:09.011492Z",
     "iopub.status.idle": "2025-12-14T08:26:09.016927Z",
     "shell.execute_reply": "2025-12-14T08:26:09.015907Z",
     "shell.execute_reply.started": "2025-12-14T08:26:09.011780Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_accession(header):\n",
    "    \"\"\"Extract accession from a FASTA header like >sp|A0JP26|POTB3_HUMAN\"\"\"\n",
    "    parts = header.lstrip('>').split('|')\n",
    "    if len(parts) >= 2:\n",
    "        return parts[1]\n",
    "    else:\n",
    "        return header.lstrip('>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:11.681643Z",
     "iopub.status.busy": "2025-12-14T08:26:11.681332Z",
     "iopub.status.idle": "2025-12-14T08:26:11.769480Z",
     "shell.execute_reply": "2025-12-14T08:26:11.768370Z",
     "shell.execute_reply.started": "2025-12-14T08:26:11.681621Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "\n",
    "bio_properties = [\"Hydrophobicity\", \"Charge\", \"VanDerWaals\", \"Polarity\",\n",
    "                  \"Polarizability\", \"SecondStructure\", \"Solvent\"]\n",
    "\n",
    "def load_fasta_features(fasta_path):\n",
    "    \"\"\"\n",
    "    Load sequences from a FASTA file, extract features, and return\n",
    "    a feature matrix X and a list of protein IDs.\n",
    "    \"\"\"\n",
    "    ids = []\n",
    "    feats = []\n",
    "\n",
    "    for record in SeqIO.parse(fasta_path, \"fasta\"):\n",
    "        protein_id = extract_accession(record.id)\n",
    "        seq = str(record.seq).upper()\n",
    "\n",
    "        # --- Feature extraction ---\n",
    "        x = []\n",
    "        x.extend(naive_freq(seq))\n",
    "        for prop in bio_properties:\n",
    "            x.extend(aa_ctd(seq, prop))\n",
    "        x.extend(dipeptide_composition(seq))\n",
    "\n",
    "        ids.append(protein_id)\n",
    "        feats.append(x)\n",
    "\n",
    "    X = np.vstack(feats)\n",
    "    return ids, X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:13.744219Z",
     "iopub.status.busy": "2025-12-14T08:26:13.743876Z",
     "iopub.status.idle": "2025-12-14T08:26:15.208353Z",
     "shell.execute_reply": "2025-12-14T08:26:15.207207Z",
     "shell.execute_reply.started": "2025-12-14T08:26:13.744185Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/kaggle/working/cafa6_data/Train/train_terms.tsv\", sep=\"\\t\",\n",
    "                 names=[\"EntryID\", \"GO\", \"Ont\"])\n",
    "\n",
    "df[\"EntryID\"] = df[\"EntryID\"].str.strip()\n",
    "df[\"GO\"] = df[\"GO\"].str.strip()\n",
    "df[\"Ont\"] = df[\"Ont\"].str.strip()\n",
    "\n",
    "labels_MF = {}\n",
    "labels_BP = {}\n",
    "labels_CC = {}\n",
    "\n",
    "for entry, go, ont in zip(df[\"EntryID\"], df[\"GO\"], df[\"Ont\"]):\n",
    "    if ont == \"F\":\n",
    "        labels_MF.setdefault(entry, []).append(go)\n",
    "    elif ont == \"P\":\n",
    "        labels_BP.setdefault(entry, []).append(go)\n",
    "    elif ont == \"C\":\n",
    "        labels_CC.setdefault(entry, []).append(go)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:15.877051Z",
     "iopub.status.busy": "2025-12-14T08:26:15.876666Z",
     "iopub.status.idle": "2025-12-14T08:26:15.884549Z",
     "shell.execute_reply": "2025-12-14T08:26:15.883301Z",
     "shell.execute_reply.started": "2025-12-14T08:26:15.877024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def build_Y(train_ids, label_dict):\n",
    "    # collect all GO terms for this ontology\n",
    "    all_terms = sorted({go for gos in label_dict.values() for go in gos})\n",
    "    term_to_index = {go: i for i, go in enumerate(all_terms)}\n",
    "\n",
    "    Y = np.zeros((len(train_ids), len(all_terms)), dtype=np.uint8)\n",
    "\n",
    "    for i, pid in enumerate(train_ids):\n",
    "        if pid in label_dict:\n",
    "            for go in label_dict[pid]:\n",
    "                j = term_to_index[go]\n",
    "                Y[i, j] = 1\n",
    "\n",
    "    return Y, term_to_index, all_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:26:51.303131Z",
     "iopub.status.busy": "2025-12-14T08:26:51.302301Z",
     "iopub.status.idle": "2025-12-14T08:26:56.862876Z",
     "shell.execute_reply": "2025-12-14T08:26:56.862034Z",
     "shell.execute_reply.started": "2025-12-14T08:26:51.303097Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# train_ids = np.load(\"/kaggle/input/training-data/training_data.npz\")[\"Train_ID\"]\n",
    "# X_train = np.load(\"/kaggle/input/training-data/training_data.npz\")[\"X_train\"]\n",
    "train_ids = np.load(\"/kaggle/input/cafa-6-t5-embeddings/train_ids.npy\")\n",
    "X_train = np.load(\"/kaggle/input/cafa-6-t5-embeddings/train_embeds.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:27:09.389489Z",
     "iopub.status.busy": "2025-12-14T08:27:09.389173Z",
     "iopub.status.idle": "2025-12-14T08:27:09.593146Z",
     "shell.execute_reply": "2025-12-14T08:27:09.591820Z",
     "shell.execute_reply.started": "2025-12-14T08:27:09.389467Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Y_MF, mf_term_to_idx, mf_terms = build_Y(train_ids, labels_MF)\n",
    "Y_BP, bp_term_to_idx, bp_terms = build_Y(train_ids, labels_BP)\n",
    "Y_CC, cc_term_to_idx, cc_terms = build_Y(train_ids, labels_CC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:27:14.280986Z",
     "iopub.status.busy": "2025-12-14T08:27:14.280637Z",
     "iopub.status.idle": "2025-12-14T08:28:10.897933Z",
     "shell.execute_reply": "2025-12-14T08:28:10.896747Z",
     "shell.execute_reply.started": "2025-12-14T08:27:14.280961Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training PCA + KNN...\n",
      "(10, 6616)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Reduce X dimensionality from 567 → 100\n",
    "pca = PCA(n_components=100)\n",
    "X_reduced = pca.fit_transform(X_train)\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=5,\n",
    "    metric=\"euclidean\",\n",
    "    weights=\"distance\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"Training PCA + KNN...\")\n",
    "knn.fit(X_reduced, Y_MF)\n",
    "\n",
    "# Prediction\n",
    "pred = knn.predict(X_reduced[:10])\n",
    "print(pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:29:17.765682Z",
     "iopub.status.busy": "2025-12-14T08:29:17.764715Z",
     "iopub.status.idle": "2025-12-14T08:31:44.735321Z",
     "shell.execute_reply": "2025-12-14T08:31:44.734274Z",
     "shell.execute_reply.started": "2025-12-14T08:29:17.765637Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, weights=&#x27;distance&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(metric=&#x27;euclidean&#x27;, n_jobs=-1, weights=&#x27;distance&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(metric='euclidean', n_jobs=-1, weights='distance')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same PCA trained on X_train\n",
    "pca = PCA(n_components=100)\n",
    "X_train_reduced = pca.fit_transform(X_train)\n",
    "\n",
    "# BP\n",
    "knn_bp = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\", weights=\"distance\", n_jobs=-1)\n",
    "knn_bp.fit(X_train_reduced, Y_BP)\n",
    "\n",
    "# CC\n",
    "knn_cc = KNeighborsClassifier(n_neighbors=5, metric=\"euclidean\", weights=\"distance\", n_jobs=-1)\n",
    "knn_cc.fit(X_train_reduced, Y_CC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:33:17.305812Z",
     "iopub.status.busy": "2025-12-14T08:33:17.305470Z",
     "iopub.status.idle": "2025-12-14T08:33:32.060313Z",
     "shell.execute_reply": "2025-12-14T08:33:32.059256Z",
     "shell.execute_reply.started": "2025-12-14T08:33:17.305786Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# test_data = np.load(\"/kaggle/input/test-set/test_data.npz\")\n",
    "# print(test_data)\n",
    "X_test = np.load(\"/kaggle/input/cafa-6-t5-embeddings/test_embeds.npy\")\n",
    "test_ids = np.load(\"/kaggle/input/cafa-6-t5-embeddings/test_ids.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:33:34.328421Z",
     "iopub.status.busy": "2025-12-14T08:33:34.327966Z",
     "iopub.status.idle": "2025-12-14T08:33:34.337785Z",
     "shell.execute_reply": "2025-12-14T08:33:34.336504Z",
     "shell.execute_reply.started": "2025-12-14T08:33:34.328395Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82404, 6616)\n",
      "(82404, 16858)\n",
      "(82404, 2651)\n",
      "6616\n",
      "16858\n",
      "2651\n",
      "['A0A0C5B5G6' 'A0A1B0GTW7' 'A0JNW5' 'A0JP26' 'A0PK11']\n"
     ]
    }
   ],
   "source": [
    "print(Y_MF.shape)\n",
    "print(Y_BP.shape)\n",
    "print(Y_CC.shape)\n",
    "print(len(mf_terms))\n",
    "print(len(bp_terms))\n",
    "print(len(cc_terms))\n",
    "print(test_ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:33:36.977424Z",
     "iopub.status.busy": "2025-12-14T08:33:36.977010Z",
     "iopub.status.idle": "2025-12-14T08:33:38.945235Z",
     "shell.execute_reply": "2025-12-14T08:33:38.944188Z",
     "shell.execute_reply.started": "2025-12-14T08:33:36.977394Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224309, 100)\n"
     ]
    }
   ],
   "source": [
    "X_test_reduced = pca.transform(X_test)\n",
    "print(X_test_reduced.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:33:45.752562Z",
     "iopub.status.busy": "2025-12-14T08:33:45.752242Z",
     "iopub.status.idle": "2025-12-14T08:33:46.264240Z",
     "shell.execute_reply": "2025-12-14T08:33:46.263110Z",
     "shell.execute_reply.started": "2025-12-14T08:33:45.752540Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. GO Term Loading and Mapping ---\n",
    "def load_go_terms(obo_path):\n",
    "    \"\"\"Parses GO.obo to map GO IDs to their root ontology (MFO, BPO, CCO).\"\"\"\n",
    "    go_terms = {}\n",
    "    current_term = None\n",
    "    \n",
    "    # Read the GO.obo file\n",
    "    with open(obo_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith('[Term]'):\n",
    "                current_term = {}\n",
    "            elif current_term is not None:\n",
    "                if line.startswith('id:'):\n",
    "                    current_term['id'] = line.split(': ')[1]\n",
    "                elif line.startswith('namespace:'):\n",
    "                    namespace = line.split(': ')[1]\n",
    "                    if 'biological_process' in namespace:\n",
    "                        current_term['root'] = 'BPO'\n",
    "                    elif 'molecular_function' in namespace:\n",
    "                        current_term['root'] = 'MFO'\n",
    "                    elif 'cellular_component' in namespace:\n",
    "                        current_term['root'] = 'CCO'\n",
    "                elif line == '':\n",
    "                    if current_term.get('id') and current_term.get('root'):\n",
    "                        go_terms[current_term['id']] = current_term['root']\n",
    "                    current_term = None\n",
    "    return go_terms\n",
    "\n",
    "# Load the GO terms dictionary\n",
    "# NOTE: Update the path to 'go-basic.obo' if needed for your environment.\n",
    "GO_OBO_PATH = '/kaggle/working/cafa6_data/Train/go-basic.obo' \n",
    "go_terms_dict = load_go_terms(GO_OBO_PATH)\n",
    "\n",
    "\n",
    "# --- 2. Ensemble Class ---\n",
    "class ProteinPredictions:\n",
    "    \"\"\"Stores and merges predictions from multiple sources.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.predictions = {}\n",
    "\n",
    "    def add_prediction(self, protein, go_term, score, branch, bonus=0):\n",
    "        # If the protein is not already in the storage, initialize its structure\n",
    "        if protein not in self.predictions:\n",
    "            self.predictions[protein] = {'CCO': {}, 'MFO': {}, 'BPO': {}}\n",
    "        \n",
    "        score = float(score)\n",
    "\n",
    "        if go_term in self.predictions[protein][branch]:\n",
    "            # This logic rewards consensus: if a term is predicted by both models, \n",
    "            # the bonus is added to the highest score found so far.\n",
    "            current_score = self.predictions[protein][branch][go_term]\n",
    "            new_score = max(current_score, score) + bonus\n",
    "            self.predictions[protein][branch][go_term] = new_score\n",
    "        else:\n",
    "            self.predictions[protein][branch][go_term] = score\n",
    "\n",
    "        # Ensure that the score does not exceed 1\n",
    "        if self.predictions[protein][branch][go_term] > 1:\n",
    "            self.predictions[protein][branch][go_term] = 1\n",
    "\n",
    "    def get_predictions(self, output_file='submission_ensemble.tsv', top=35):\n",
    "        \"\"\"Exports the merged predictions to a CAFA-formatted file.\"\"\"\n",
    "        with open(output_file, 'w') as f:\n",
    "            # Write CAFA headers\n",
    "            for protein, branches in tqdm(self.predictions.items(), desc=\"Writing Final Submission\"):\n",
    "                for branch, go_terms in branches.items():\n",
    "                    # Sort GO terms by score in descending order and select the top ones\n",
    "                    top_go_terms = sorted(go_terms.items(), key=lambda x: x[1], reverse=True)[:top]\n",
    "                    \n",
    "                    # Write each of the top predictions to the file\n",
    "                    for go_term, score in top_go_terms:\n",
    "                        f.write(f\"{protein}\\t{go_term}\\t{score:.6f}\\n\")\n",
    "\n",
    "        print(f\"\\nEnsemble CAFA submission saved to: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:39:36.555283Z",
     "iopub.status.busy": "2025-12-14T08:39:36.554933Z",
     "iopub.status.idle": "2025-12-14T10:33:25.042440Z",
     "shell.execute_reply": "2025-12-14T10:33:25.041364Z",
     "shell.execute_reply.started": "2025-12-14T08:39:36.555261Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing proteins: 100%|██████████| 225/225 [1:52:49<00:00, 30.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch CAFA submission saved to: ctd_temp_submission.tsv\n",
      "Loading CTD predictions from: ctd_temp_submission.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing CTD scores: 7850815it [00:20, 389919.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading BLAST predictions from: /kaggle/input/blast-quick-sprof-zero-pred/submission.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing BLAST scores: 11977931it [00:26, 454366.27it/s]\n",
      "Writing Final Submission: 100%|██████████| 279437/279437 [00:12<00:00, 23012.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ensemble CAFA submission saved to: final_ensemble_submission.tsv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Generate CTD-SVM Baseline (P_CTD) ---\n",
    "CTD_SUBMISSION_FILE = \"ctd_temp_submission.tsv\"\n",
    "\n",
    "# Use your existing batch submission function to generate the CTD-based predictions\n",
    "make_cafa_submission_batch(\n",
    "    test_ids,\n",
    "    X_test_reduced,\n",
    "    knn, mf_terms,\n",
    "    knn_bp, bp_terms,\n",
    "    knn_cc, cc_terms,\n",
    "    output_path=CTD_SUBMISSION_FILE, # Saves your CTD predictions to a temp file\n",
    "    batch_size=1000\n",
    ")\n",
    "\n",
    "# --- 2. Initialize Ensemble and Load Predictions ---\n",
    "predictor = ProteinPredictions()\n",
    "\n",
    "# Load CTD-based predictions (P_CTD)\n",
    "print(f\"Loading CTD predictions from: {CTD_SUBMISSION_FILE}\")\n",
    "with open(CTD_SUBMISSION_FILE, 'r') as f:\n",
    "    for item in tqdm(f, desc=\"Processing CTD scores\"):\n",
    "        if item.startswith('AUTHOR') or item.startswith('MODEL') or item.startswith('END'):\n",
    "            continue\n",
    "        try:\n",
    "            protein_id, go_term, score_str = item.strip().split('\\t')\n",
    "            score = float(score_str)\n",
    "            if go_term in go_terms_dict:\n",
    "                root = go_terms_dict[go_term]\n",
    "                # Add CTD predictions (no bonus yet)\n",
    "                predictor.add_prediction(protein_id, go_term, score, root, bonus=0.0)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "# Load BLAST-based predictions (P_BLAST)\n",
    "BLAST_SUBMISSION_PATH = '/kaggle/input/blast-quick-sprof-zero-pred/submission.tsv' \n",
    "print(f\"\\nLoading BLAST predictions from: {BLAST_SUBMISSION_PATH}\")\n",
    "with open(BLAST_SUBMISSION_PATH, 'r') as f:\n",
    "    for item in tqdm(f, desc=\"Processing BLAST scores\"):\n",
    "        try:\n",
    "            # Note: The format of this file might have a different column order (often ProteinID, GO_TERM, Score).\n",
    "            # We assume the standard three-column CAFA output.\n",
    "            protein_id, go_term, score_str = item.strip().split('\\t')\n",
    "            score = float(score_str)\n",
    "            if go_term in go_terms_dict:\n",
    "                root = go_terms_dict[go_term]\n",
    "                # Add BLAST predictions with a slight bonus to reward consensus\n",
    "                predictor.add_prediction(protein_id, go_term, score, root, bonus=0.01)\n",
    "        except ValueError:\n",
    "            # Handle potential header lines or formatting issues in the BLAST file\n",
    "            continue\n",
    "        except KeyError:\n",
    "            # Handle GO terms not found in the GO_terms_dict (non-evaluatable or obsolete)\n",
    "            continue\n",
    "            \n",
    "# --- 3. Final Submission Export ---\n",
    "FINAL_SUBMISSION_FILE = \"final_ensemble_submission.tsv\"\n",
    "predictor.get_predictions(FINAL_SUBMISSION_FILE, top=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T08:39:30.077800Z",
     "iopub.status.busy": "2025-12-14T08:39:30.077487Z",
     "iopub.status.idle": "2025-12-14T08:39:30.091445Z",
     "shell.execute_reply": "2025-12-14T08:39:30.090316Z",
     "shell.execute_reply.started": "2025-12-14T08:39:30.077779Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# (Assume the get_probabilities function is the robust, RAM-efficient version)\n",
    "# ...\n",
    "def get_probabilities(knn_model, X_batch):\n",
    "    \"\"\"\n",
    "    The definitive, RAM-efficient method to get the (N_batch, N_terms) score matrix,\n",
    "    explicitly handling the single-column collapse without excessive memory use.\n",
    "    \"\"\"\n",
    "    # 1. Get the list of probability arrays (one array per term)\n",
    "    prob_list = knn_model.predict_proba(X_batch)\n",
    "    N_batch = X_batch.shape[0]\n",
    "    N_terms = len(prob_list)\n",
    "    \n",
    "    # 2. Pre-allocate the final score matrix (N_batch rows, N_terms columns)\n",
    "    # Using float32 saves half the memory compared to float64.\n",
    "    final_scores = np.empty((N_batch, N_terms), dtype=np.float32)\n",
    "    \n",
    "    # 3. Populate the matrix column-by-column, handling the size collapse\n",
    "    for j, P_term in enumerate(prob_list):\n",
    "        # P_term shape is (N_batch, N_classes)\n",
    "        \n",
    "        # Check if the class dimension has collapsed (size 1) or is standard (size 2)\n",
    "        if P_term.shape[1] == 2:\n",
    "            # Standard: Extract the positive class probability (index 1)\n",
    "            final_scores[:, j] = P_term[:, 1]\n",
    "        elif P_term.shape[1] == 1:\n",
    "            # Collapsed: Assume the single column is the score we want (index 0)\n",
    "            final_scores[:, j] = P_term[:, 0]\n",
    "        else:\n",
    "            raise ValueError(\"Unexpected number of classes for a GO term.\")\n",
    "            \n",
    "    return final_scores\n",
    "\n",
    "def make_cafa_submission_batch(\n",
    "    test_ids,\n",
    "    X_test_reduced,\n",
    "    knn_mf, mf_terms,\n",
    "    knn_bp, bp_terms,\n",
    "    knn_cc, cc_terms,\n",
    "    output_path=\"cafa_submission.tsv\",\n",
    "    threshold=0.1,\n",
    "    top_k=35,  # ADDED: Maximum number of predictions per protein\n",
    "    batch_size=1000\n",
    "):\n",
    "    N = len(test_ids)\n",
    "\n",
    "    with open(output_path, \"w\") as f:\n",
    "        # Loop over batch indices\n",
    "        for start in tqdm(range(0, N, batch_size), desc=\"Processing proteins\"):\n",
    "            end = min(start + batch_size, N)\n",
    "\n",
    "            X_batch = X_test_reduced[start:end]\n",
    "            ids_batch = test_ids[start:end]\n",
    "\n",
    "            # 1. Get the Score Matrices (RAM-efficiently)\n",
    "            prob_mf_matrix = get_probabilities(knn_mf, X_batch)\n",
    "            prob_bp_matrix = get_probabilities(knn_bp, X_batch)\n",
    "            prob_cc_matrix = get_probabilities(knn_cc, X_batch)\n",
    "\n",
    "            # 2. Write rows to file\n",
    "            for i in range(len(ids_batch)):\n",
    "                pid = ids_batch[i]\n",
    "                \n",
    "                # Collect all filtered scores for the current protein\n",
    "                all_protein_predictions = []\n",
    "                \n",
    "                ontologies = [\n",
    "                    (prob_mf_matrix[i], mf_terms),\n",
    "                    (prob_bp_matrix[i], bp_terms),\n",
    "                    (prob_cc_matrix[i], cc_terms)\n",
    "                ]\n",
    "\n",
    "                # Loop through each ontology\n",
    "                for scores, terms in ontologies:\n",
    "                    # Apply the score threshold filter first\n",
    "                    mask = scores >= threshold\n",
    "                    \n",
    "                    filtered_scores = scores[mask]\n",
    "                    filtered_terms = np.array(terms)[mask]\n",
    "\n",
    "                    # Collect the valid predictions\n",
    "                    for go, score in zip(filtered_terms, filtered_scores):\n",
    "                        all_protein_predictions.append((go, score))\n",
    "\n",
    "                # --- NEW STEP: Apply Top-K Filter ---\n",
    "                if all_protein_predictions:\n",
    "                    # Sort by score in descending order\n",
    "                    all_protein_predictions.sort(key=lambda x: x[1], reverse=True)\n",
    "                    \n",
    "                    # Take only the top K predictions (e.g., 35)\n",
    "                    top_k_predictions = all_protein_predictions[:top_k]\n",
    "                    \n",
    "                    # Write the final, filtered predictions to the file\n",
    "                    for go_term, score in top_k_predictions:\n",
    "                        f.write(f\"{pid}\\t{go_term}\\t{score:.6f}\\n\")\n",
    "\n",
    "        # Write the required footer for CAFA format\n",
    "        # f.write(\"END\\n\") # Commented out if handled in the caller function\n",
    "\n",
    "    print(f\"\\nBatch CAFA submission saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-11T13:04:17.006900Z",
     "iopub.status.busy": "2025-12-11T13:04:17.006056Z",
     "iopub.status.idle": "2025-12-11T13:49:22.926565Z",
     "shell.execute_reply": "2025-12-11T13:49:22.925353Z",
     "shell.execute_reply.started": "2025-12-11T13:04:17.006872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "make_cafa_submission_batch(\n",
    "    test_ids,\n",
    "    X_test_reduced,\n",
    "    knn, mf_terms,\n",
    "    knn_bp, bp_terms,\n",
    "    knn_cc, cc_terms,\n",
    "    output_path=\"submission.tsv\",\n",
    "    batch_size=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# test_ids, X_test = load_fasta_features(\"/kaggle/working/cafa6_data/Test/testsuperset.fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# np.savez('/kaggle/working/test_data.npz', \n",
    "#          test_ids=test_ids, \n",
    "#          X_test=X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ensemble Stacking**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "N, L = y_train.shape\n",
    "Z_knn   = np.zeros((N, L))\n",
    "Z_mlp   = np.zeros((N, L))\n",
    "Z_blast = np.zeros((N, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for fold, (tr, val) in enumerate(kf.split(X_ids)):\n",
    "\n",
    "    # ---- KNN ----\n",
    "    knn = KNNModel(...)\n",
    "    knn.fit(embeddings[tr], y_train[tr])\n",
    "    Z_knn[val] = knn.predict_proba(embeddings[val])\n",
    "\n",
    "    # ---- MLP ----\n",
    "    mlp = train_mlp(esm[tr], y_train[tr])\n",
    "    Z_mlp[val] = mlp.predict_proba(esm[val])\n",
    "\n",
    "    # ---- BLAST ----\n",
    "    blast_db = make_blast_db(seqs[tr])\n",
    "    Z_blast[val] = blast_predict(\n",
    "        queries=seqs[val],\n",
    "        db=blast_db\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For GO term g\n",
    "X_meta_g = np.stack([\n",
    "    Z_knn[:, g],\n",
    "    Z_mlp[:, g],\n",
    "    Z_blast[:, g]\n",
    "], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "meta_models = []\n",
    "\n",
    "for g in range(L):\n",
    "    meta = LogisticRegression(\n",
    "        penalty=\"l2\",\n",
    "        C=1.0,\n",
    "        max_iter=1000\n",
    "    )\n",
    "    meta.fit(X_meta_g, y_train[:, g])\n",
    "    meta_models.append(meta)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3590060,
     "sourceId": 6247561,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8688768,
     "sourceId": 13665986,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8984734,
     "sourceId": 14106315,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8984889,
     "sourceId": 14106507,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
